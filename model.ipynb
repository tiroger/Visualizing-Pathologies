{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, metrics\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.8.0\n",
      "Keras version: 2.8.0\n",
      "Matplotlib version: 3.5.1\n",
      "OpenCV version: 4.9.0\n"
     ]
    }
   ],
   "source": [
    "# Versions of each library\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {tf.keras.__version__}\")\n",
    "print(f\"Matplotlib version: {plt.matplotlib.__version__}\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './images/train'\n",
    "validation_path = './images/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8184 images belonging to 3 classes.\n",
      "Found 965 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,  # Assuming train_dir is defined\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')  # Change for multi-class\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_path,  # Assuming validation_dir is defined\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')  # Change for multi-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')  # Change for three classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=metrics.AUC(multi_label=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 16:18:12.740565: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 0.4376 - auc_1: 0.9298WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 15s 141ms/step - loss: 0.4376 - auc_1: 0.9298 - val_loss: 0.3993 - val_auc_1: 0.9753\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.4430 - auc_1: 0.9286\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.3940 - auc_1: 0.9373\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.4158 - auc_1: 0.9376\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.4002 - auc_1: 0.9412\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.3549 - auc_1: 0.9581\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.3394 - auc_1: 0.9616\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.3300 - auc_1: 0.9555\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.3314 - auc_1: 0.9598\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.3500 - auc_1: 0.9587\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.3009 - auc_1: 0.9709\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.3242 - auc_1: 0.9652\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.3182 - auc_1: 0.9646\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.2570 - auc_1: 0.9765\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.3246 - auc_1: 0.9555\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.3167 - auc_1: 0.9628\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.2681 - auc_1: 0.9726\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.2594 - auc_1: 0.9774\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.2505 - auc_1: 0.9777\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.2454 - auc_1: 0.9796\n"
     ]
    }
   ],
   "source": [
    "class_weights = {0: 1.,  # weight for class 0 (Benign)\n",
    "                 1: 1.,  # weight for class 1 (Malignant)\n",
    "                 2: 5.}  # weight for class 2 (Normal, under-represented)\n",
    "\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,  # Depends on your dataset size\n",
    "      epochs=20,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      class_weight=class_weights\n",
    "      ) # Depends on your dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'benign': 0, 'malignant': 1, 'normal': 2}\n"
     ]
    }
   ],
   "source": [
    "# Print classes\n",
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'auc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# # Extracting the history of training and validation accuracy and loss\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# acc = history.history['accuracy']\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# val_acc = history.history['val_accuracy']\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Extracting the history of training and validation AUC and loss\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m auc \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     33\u001b[0m val_auc \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_auc\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     34\u001b[0m loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'auc'"
     ]
    }
   ],
   "source": [
    "# # Extracting the history of training and validation accuracy and loss\n",
    "# acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "# epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# # Plotting training and validation accuracy\n",
    "# plt.figure(figsize=(12, 5))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "# # plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# # Plotting training and validation loss\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# # plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# Extracting the history of training and validation AUC and loss\n",
    "auc = history.history['auc']\n",
    "val_auc = history.history['val_auc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(auc) + 1)\n",
    "\n",
    "# Plotting training and validation AUC\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, auc, 'bo', label='Training AUC')\n",
    "plt.plot(epochs, val_auc, 'b', label='Validation AUC')\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting training and validation loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 965 images belonging to 3 classes.\n",
      "31/31 [==============================] - 2s 56ms/step - loss: 0.3969 - auc_1: 0.9581\n",
      "Test AUC: 95.8%\n",
      "Test Loss: 0.4\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_path,  # Assuming validation_dir is defined\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')  # Change for multi-class\n",
    "\n",
    "test_loss, test_auc = model.evaluate(validation_generator)\n",
    "print(f\"Test AUC: {test_auc*100:.1f}%\")\n",
    "print(f\"Test Loss: {test_loss:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model as a `.keras` zip archive.\n",
    "model.save('model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_20 (Conv2D)          (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 74, 74, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 36, 36, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 17, 17, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 15, 15, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 7, 7, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               3211776   \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,454,147\n",
      "Trainable params: 3,454,147\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('model.keras')\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the use of a pre-trained model like MobileNet for transfer learning\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "# Add custom layers on top for our specific problem\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)  # Add dropout\n",
    "predictions = Dense(3, activation='softmax')(x)  # Change for three classes\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,  # Depends on your dataset size\n",
    "      epochs=15,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)  # Depends on your dataset size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultrasoundviz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
